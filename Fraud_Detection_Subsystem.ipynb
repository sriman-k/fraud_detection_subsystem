{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "bc90ec80-5884-412b-bb3f-7dc74ea4d6a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flagged transactions saved to 'flagged_transactions.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Load transaction dataset\n",
    "transactions_file = \"/Users/KundaSwami_1/Downloads/Synthetic_Fraud_Dataset.csv\"  # Update with actual file path\n",
    "txn_df = pd.read_csv(transactions_file, parse_dates=['timestamp'])\n",
    "\n",
    "# Load MCC dataset\n",
    "mcc_file = \"/Users/KundaSwami_1/Downloads/mcc_codes.csv\"  # Update with actual file path\n",
    "mcc_df = pd.read_csv(mcc_file)\n",
    "\n",
    "# Normalize column names to lowercase\n",
    "mcc_df.columns = mcc_df.columns.str.lower()\n",
    "\n",
    "# Adjust MCC dictionary creation based on actual column names\n",
    "mcc_dict = dict(zip(mcc_df['mcc'], mcc_df['combined_description']))\n",
    "\n",
    "# --- MCC VALIDATION ---\n",
    "def validate_merchant_mcc(row):\n",
    "    mcc = row.get('merchant_mcc', None)\n",
    "    name = row['merchant_name'].lower()\n",
    "    if mcc in mcc_dict:\n",
    "        category = mcc_dict[mcc].lower()\n",
    "        return any(word in name for word in category.split())\n",
    "    return False\n",
    "\n",
    "txn_df['mcc_valid'] = txn_df.apply(validate_merchant_mcc, axis=1)\n",
    "\n",
    "# --- FEATURE ENGINEERING ---\n",
    "txn_df['txn_hour'] = txn_df['timestamp'].dt.hour\n",
    "txn_df['txn_dow'] = txn_df['timestamp'].dt.dayofweek\n",
    "txn_df['amt_to_avg_ratio'] = txn_df['amount'] / txn_df.groupby('user_id')['amount'].transform('mean')\n",
    "\n",
    "# Rule 1: Standard deviation-based anomaly detection\n",
    "txn_df['amt_std'] = txn_df.groupby('user_id')['amount'].transform('std')\n",
    "txn_df['amt_mean'] = txn_df.groupby('user_id')['amount'].transform('mean')\n",
    "txn_df['amt_z_score'] = (txn_df['amount'] - txn_df['amt_mean']) / txn_df['amt_std']\n",
    "txn_df['rule_std_dev'] = txn_df['amt_z_score'].abs() > 2.5  # Adjusted threshold\n",
    "\n",
    "# Rule 2: Unusually high transaction volume\n",
    "txn_df['user_txn_count'] = txn_df.groupby('user_id')['timestamp'].transform('count')\n",
    "txn_df['rule_unusual_activity'] = txn_df['user_txn_count'] > txn_df['user_txn_count'].quantile(0.98)\n",
    "\n",
    "# --- UNSUPERVISED LEARNING ---\n",
    "features = ['amount', 'txn_hour', 'txn_dow', 'amt_to_avg_ratio']\n",
    "X = txn_df[features].fillna(0)\n",
    "\n",
    "# GMM Anomaly Detection\n",
    "gmm = GaussianMixture(n_components=4, covariance_type='full', random_state=42)\n",
    "gmm.fit(X)\n",
    "txn_df['gmm_score'] = -gmm.score_samples(X)\n",
    "\n",
    "# Isolation Forest Anomaly Detection\n",
    "iso = IsolationForest(n_estimators=100, contamination=0.005, random_state=42)\n",
    "iso.fit(X)\n",
    "txn_df['iso_score'] = -iso.decision_function(X)\n",
    "txn_df['iso_anomaly'] = iso.predict(X)  # -1 = anomaly\n",
    "\n",
    "# --- RULE-BASED FRAUD DETECTION ---\n",
    "# Rule 3: Large transactions relative to user spending pattern\n",
    "txn_df['rule_large'] = txn_df['amount'] > (txn_df['amt_mean'] + 2.5 * txn_df['amt_std'])\n",
    "\n",
    "# Rule 4: High transaction velocity (sorted by timestamp for accuracy)\n",
    "txn_df = txn_df.sort_values(['user_id', 'timestamp'])\n",
    "txn_df['prev_txn_time'] = txn_df.groupby('user_id')['timestamp'].shift(1)\n",
    "txn_df['time_since_prev'] = (txn_df['timestamp'] - txn_df['prev_txn_time']).dt.total_seconds()\n",
    "txn_df['recent_txn_count'] = txn_df.groupby('user_id')['timestamp'].diff().lt(pd.Timedelta(seconds=300)).astype(int).groupby(txn_df['user_id']).cumsum()\n",
    "txn_df['rule_velocity'] = txn_df['recent_txn_count'] > 4\n",
    "\n",
    "# Rule 5: Transactions at unusual times (expanded to 0-6 AM)\n",
    "txn_df['rule_time'] = txn_df['txn_hour'].isin([0, 1, 2, 3, 4])\n",
    "\n",
    "# Rule 6: ML-based anomaly detection\n",
    "txn_df['rule_ml_anomaly'] = txn_df['iso_anomaly'] == -1\n",
    "\n",
    "# Rule 7: Rare merchants\n",
    "txn_df['small_txn'] = txn_df['amount'] < 5\n",
    "txn_df['small_streak'] = txn_df.groupby('user_id')['small_txn'].transform(lambda x: x.groupby((x != x.shift()).cumsum()).cumsum())\n",
    "txn_df['rule_structuring'] = txn_df['small_streak'] >= 2\n",
    "\n",
    "merchant_counts = txn_df['merchant_name'].value_counts()\n",
    "threshold = merchant_counts.quantile(0.05)\n",
    "rare_merchants = set(merchant_counts[merchant_counts <= threshold].index)\n",
    "txn_df['rule_deviation'] = txn_df['merchant_name'].isin(rare_merchants) & (txn_df['amount'] > txn_df['amount'].quantile(0.85))\n",
    "\n",
    "# --- FINAL FRAUD FLAGGING ---\n",
    "txn_df['fraud_risk_score'] = txn_df[['gmm_score', 'iso_score']].sum(axis=1)\n",
    "fraud_threshold = txn_df[txn_df['is_fraud'] == True]['fraud_risk_score'].quantile(0.85)\n",
    "txn_df['is_fraud_flagged'] = (\n",
    "    (txn_df[['rule_large', 'rule_std_dev', 'rule_velocity', 'rule_time', 'rule_deviation', 'rule_unusual_activity', 'rule_ml_anomaly']].sum(axis=1) > 3) | \n",
    "    ((txn_df['fraud_risk_score'] > fraud_threshold) & (txn_df['iso_anomaly'] == -1))\n",
    ")\n",
    "\n",
    "# Save flagged transactions\n",
    "flagged_transactions = txn_df[txn_df['is_fraud_flagged']]\n",
    "flagged_transactions.to_csv(\"flagged_transactions.csv\", index=False)\n",
    "\n",
    "print(\"Flagged transactions saved to 'flagged_transactions.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "id": "8aa7d51d-2358-43af-b581-afce33d3611d",
   "metadata": {},
   "outputs": [],
   "source": [
    "flagged_transactions_file = \"flagged_transactions.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "id": "e06bf16c-7b03-4606-af11-d2a521c85256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_fraud_flagged\n",
      "False    9923\n",
      "True       77\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(txn_df['is_fraud_flagged'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9d050d-0a0f-4175-8840-df7645b17e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98505af1-601a-480c-ae4f-d8d7ac3e81cd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
